{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8070574",
   "metadata": {},
   "source": [
    "# Import the packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b83238",
   "metadata": {},
   "source": [
    "We will use csv so we can write our results to a csv file later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2b99b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f1962",
   "metadata": {},
   "source": [
    "# Setup the URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53126d4d",
   "metadata": {},
   "source": [
    "The template URL for reed jobs is https://www.reed.co.uk/jobs/{position}-in-{location} We need to define a function that will allow us to input what job position and location we want to search for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852d32ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(position, location):\n",
    "    template = 'https://www.reed.co.uk/jobs/{}-jobs' #web address template\n",
    "    position = position.replace(' ','-') #replaces the spaces with plus in url\n",
    "    location = location.replace(' ', '-')\n",
    "    url = template.format(position, location)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c043cb3",
   "metadata": {},
   "source": [
    "We need to call our function and assign it the the variable url as currently it is only assigned \n",
    "within the function and not globally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fed01be",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = get_url('data analyst','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e31e2c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "624b9858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6602a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d33fb25",
   "metadata": {},
   "source": [
    "# Getting the information from the HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e8ab7",
   "metadata": {},
   "source": [
    "Reed.co.uk has promoted posts that appear at the top of each search page to avoid having these\n",
    "appearing multiple times in our results we must remove them. The promoted posts have two classes job-result-card--promoted and job-result-card. We can use decompose to get rid of the job-result-card--promoted class as this class is only used for promoted posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce6f529d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for article in soup.find_all(\"article\", class_=\"job-result-card--promoted\"):\n",
    "    article.decompose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49fb73b",
   "metadata": {},
   "source": [
    "Now when we search for the class job-result-card we should only get non promoted jobs. We can use len() to check that the amount of job cards we have matched the amount of jobs on the page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "663820fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards = soup.find_all(\"article\", class_=\"job-result-card\")\n",
    "   \n",
    "len(cards)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d2dff0",
   "metadata": {},
   "source": [
    "The number of cards matches the number of non-promoted job listings per page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b491932",
   "metadata": {},
   "source": [
    "# Prototype the model with a single record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba69150",
   "metadata": {},
   "source": [
    "Now we can try getting all the information we need for just one card "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4171fd60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "card=(cards[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802a445",
   "metadata": {},
   "source": [
    "First we get the job title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "483fdcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Analyst\n"
     ]
    }
   ],
   "source": [
    "job_title = card.h3.a.get('title')\n",
    "print(job_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa789c8d",
   "metadata": {},
   "source": [
    "Then we will get the company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35ec1e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remit Resources\n"
     ]
    }
   ],
   "source": [
    "company_tag = card.find('a','gtmJobListingPostedBy')\n",
    "company = company_tag.text.strip()\n",
    "print(company)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a540236",
   "metadata": {},
   "source": [
    "Next we must get the salary. Salary isn't available for all jobs so we must create an execption to \n",
    "avoid getting an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad666175",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "£38,000 - £42,000 per annum\n"
     ]
    }
   ],
   "source": [
    "salary_tag = card.find('li','job-metadata__item--salary')\n",
    "if salary_tag:\n",
    "    salary = salary_tag.text.strip()\n",
    "else:\n",
    "    salary = ''\n",
    "print(salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7b40e",
   "metadata": {},
   "source": [
    "Next we will get the job location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daeb5bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hatfield, Hertfordshire\n"
     ]
    }
   ],
   "source": [
    "location_tag = card.find('li', 'job-metadata__item--location')\n",
    "if location_tag:\n",
    "    location = location_tag.text.strip('')\n",
    "    location = location.replace('\\n','')\n",
    "    location = location.replace('\\r ','')\n",
    "    location = location.replace('                   ','',1)\n",
    "    location = location.replace('                   ',', ',)\n",
    "\n",
    "else:\n",
    "    location = ''\n",
    "print(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351076cc",
   "metadata": {},
   "source": [
    "We will get the job type if it is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da91eedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permanent, full-time\n"
     ]
    }
   ],
   "source": [
    "jobtype_tag = card.find('li','job-metadata__item--type')\n",
    "if jobtype_tag:\n",
    "    jobtype = jobtype_tag.text.strip()\n",
    "else:\n",
    "    jobtype = ''\n",
    "print(jobtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deefceee",
   "metadata": {},
   "source": [
    "Next we check if the job is work from home like salary tag this is not always present so we must create and expection for when it is not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4f4ec40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Work from home\n"
     ]
    }
   ],
   "source": [
    "wfh_tag = card.find('li','job-metadata__item--remote')\n",
    "if wfh_tag:\n",
    "    wfh = 'Work from home'\n",
    "else:\n",
    "    wfh = 'Not Work from home'\n",
    "print(wfh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8ae010",
   "metadata": {},
   "source": [
    "Next we get the url for the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "602e0d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reed.co.uk/jobs/data-analyst/47376202?source=searchResults&filter=%2fjobs%2fdata-analyst-jobs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "job_url = 'https://www.reed.co.uk' + card.a.get('href')\n",
    "print(job_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde0017c",
   "metadata": {},
   "source": [
    "Finally we can get the begining of the job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "012c9d88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Analyst needed for this global tech business, in their North London / Hertfordshire Office (Hybrid working 2 days in the office). They are a high performance, data driven business who pride themselves on being the best at what they do. They are growing...\n"
     ]
    }
   ],
   "source": [
    "description = card.find('p', 'job-result-description__details').text.strip()\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dec2f8",
   "metadata": {},
   "source": [
    "Now we must combine all of this information into a record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a8cb923",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = (job_title, company, location, salary, wfh, jobtype, description, job_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bdb942",
   "metadata": {},
   "source": [
    "Next we check that all the information is present and displaying correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e157e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Data Analyst',\n",
       " 'Remit Resources',\n",
       " 'Hatfield, Hertfordshire',\n",
       " '£38,000 - £42,000 per annum',\n",
       " 'Not Work from home',\n",
       " 'Permanent, full-time',\n",
       " 'Data Analyst needed for this global tech business, in their North London / Hertfordshire Office (Hybrid working 2 days in the office). They are a high performance, data driven business who pride themselves on being the best at what they do. They are growing...',\n",
       " 'https://www.reed.co.uk/jobs/data-analyst/47376202?source=searchResults&filter=%2fjobs%2fdata-analyst-jobs')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271e440e",
   "metadata": {},
   "source": [
    "# Generalise model with a function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56729b79",
   "metadata": {},
   "source": [
    "Now we will use a function fo generalise the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85c97ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record(card):\n",
    "    \"\"\"Extract job data from a single record\"\"\"\n",
    "    \n",
    "    job_title = card.h3.a.get('title')\n",
    "    company_tag = card.find('a','gtmJobListingPostedBy')\n",
    "    company = company_tag.text.strip()\n",
    "    salary_tag = card.find('li','job-metadata__item--salary')\n",
    "    if salary_tag:\n",
    "        salary = salary_tag.text.strip()\n",
    "    else:\n",
    "        salary = ''\n",
    "    location_tag = card.find('li', 'job-metadata__item--location')\n",
    "    if location_tag:\n",
    "        location = location_tag.text.strip('')\n",
    "        location = location.replace('\\n','')\n",
    "        location = location.replace('\\r ','')\n",
    "        location = location.replace('                   ','',1)\n",
    "        location = location.replace('                   ',', ',)\n",
    "\n",
    "    else:\n",
    "        location = ''\n",
    "\n",
    "    description = card.find('p', 'job-result-description__details').text.strip()\n",
    "    job_url = 'https://www.reed.co.uk' + card.a.get('href')\n",
    "  \n",
    "        \n",
    "    record = (job_title, company, location, description, salary, job_url)\n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a88ac90",
   "metadata": {},
   "source": [
    "No we run the function and store the results into records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20abcf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for card in cards:\n",
    "    record = get_record(card)\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae907ff",
   "metadata": {},
   "source": [
    "Now we will write our results to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acf12cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    with open('results.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['JobTitle', 'Company', 'Location', 'Salary', 'Work From Home', 'JobUrl'])\n",
    "        writer.writerows(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e36a48",
   "metadata": {},
   "source": [
    "# Getting the next page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f3d266",
   "metadata": {},
   "source": [
    "Now we have the results for the first page we need to check if there are more pages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c9b2204",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        url = 'https://www.reed.co.uk' + soup.find('a', {'data-qa': 'nextPageLnk'}).get('href')\n",
    "    except AttributeError:\n",
    "        break\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    for article in soup.find_all(\"article\", class_=\"job-result-card--promoted\"):\n",
    "        article.decompose()\n",
    "    cards = soup.find_all(\"article\", class_=\"job-result-card\")\n",
    "\n",
    "    for card in cards:\n",
    "        record = get_record(card)\n",
    "        records.append(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a6d8f3",
   "metadata": {},
   "source": [
    "# Putting it all together "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f72d0f",
   "metadata": {},
   "source": [
    "Now we can combine all of our code together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b76f1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_url(position, location, min_salary, max_salary):\n",
    "    template = 'https://www.reed.co.uk/jobs/{}-jobs-in{}?salaryfrom={}&salaryto={}'\n",
    "    position = position.replace(' ','-')\n",
    "    url = template.format(position,location, min_salary, max_salary)\n",
    "    return url\n",
    "\n",
    "\n",
    "def get_record(card):\n",
    "    \"\"\"Extract job data from a single record\"\"\"\n",
    "    \n",
    "    job_title = card.h3.a.get('title')\n",
    "    company = card.find('a','gtmJobListingPostedBy').text.strip()\n",
    "    location_tag = card.find('li', 'job-metadata__item--location')\n",
    "    if location_tag:\n",
    "        location = location_tag.text.strip('')\n",
    "        location = location.replace('\\n','')\n",
    "        location = location.replace('\\r ','')\n",
    "        location = location.replace('                   ','',1)\n",
    "        location = location.replace('                   ',', ',)\n",
    "\n",
    "    else:\n",
    "        location = ''\n",
    "    job_url = 'https://www.reed.co.uk' + card.a.get('href')\n",
    "\n",
    "    # this does not exists for all jobs, so handle the exceptions\n",
    "    salary_tag = card.find('li','job-metadata__item--salary')\n",
    "    if salary_tag:\n",
    "        salary = salary_tag.text.strip()\n",
    "    else:\n",
    "        salary = ''  \n",
    "    \n",
    "    wfh_tag = card.find('li','job-metadata__item--remote')\n",
    "    if wfh_tag:\n",
    "        wfh = 'Work from home'\n",
    "    else:\n",
    "        wfh = 'Not work from home'\n",
    "        \n",
    "    jobtype_tag = card.find('li','job-metadata__item--type')\n",
    "    if jobtype_tag:\n",
    "        jobtype = jobtype_tag.text.strip()\n",
    "    else:\n",
    "        jobtype = ''\n",
    "        \n",
    "    description = card.find('p', 'job-result-description__details').text.strip()   \n",
    "    \n",
    "    record = (job_title, company, location, salary, wfh, jobtype, description, job_url)\n",
    "    return record\n",
    "\n",
    "\n",
    "\n",
    "def main(position, location, min_salary, max_salary):\n",
    "    records = []\n",
    "    url = get_url(position, location, min_salary, max_salary)\n",
    "    while True:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        for article in soup.find_all(\"article\", class_=\"job-result-card--promoted\"):\n",
    "            article.decompose()\n",
    "        cards = soup.find_all(\"article\", class_=\"job-result-card\")\n",
    "        for card in cards:\n",
    "            record = get_record(card)\n",
    "            records.append(record)\n",
    "        try:\n",
    "            url = 'https://www.reed.co.uk' + soup.find('a', {'data-qa': 'nextPageLnk'}).get('href')\n",
    "        except AttributeError:\n",
    "            break\n",
    "        \n",
    "    with open('results.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['JobTitle', 'Company', 'Location', 'Salary', 'Work From Home', 'Job Type', 'Job Description', 'JobUrl'])\n",
    "        writer.writerows(records)\n",
    "    #job_title, company,location, job_url, salary, wfh,      jobtype, description, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4e075c",
   "metadata": {},
   "source": [
    "We can run the function now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec5f0e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main('Data analyst','','','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de44895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
